{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae6af31",
   "metadata": {},
   "source": [
    "### Setting up the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92edbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nba_data = pd.read_csv(r\"seasons_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cd64253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6134 entries, 0 to 6133\n",
      "Data columns (total 36 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Season  6134 non-null   int64  \n",
      " 1   Player  6134 non-null   object \n",
      " 2   Pos     6134 non-null   object \n",
      " 3   Age     6134 non-null   float64\n",
      " 4   Tm      6134 non-null   object \n",
      " 5   G       6134 non-null   float64\n",
      " 6   GS      6134 non-null   float64\n",
      " 7   MPG     6134 non-null   float64\n",
      " 8   PPG     6134 non-null   float64\n",
      " 9   RPG     6134 non-null   float64\n",
      " 10  APG     6134 non-null   float64\n",
      " 11  SPG     6134 non-null   float64\n",
      " 12  BPG     6134 non-null   float64\n",
      " 13  TOPG    6134 non-null   float64\n",
      " 14  eFG%    6134 non-null   float64\n",
      " 15  FG      6134 non-null   float64\n",
      " 16  FGA     6134 non-null   float64\n",
      " 17  FG%     6134 non-null   float64\n",
      " 18  3P      6134 non-null   float64\n",
      " 19  3PA     6134 non-null   float64\n",
      " 20  3P%     6134 non-null   float64\n",
      " 21  FT      6134 non-null   float64\n",
      " 22  FTA     6134 non-null   float64\n",
      " 23  FT%     6134 non-null   float64\n",
      " 24  PFPG    6134 non-null   float64\n",
      " 25  PER     6134 non-null   float64\n",
      " 26  TS%     6134 non-null   float64\n",
      " 27  USG%    6134 non-null   float64\n",
      " 28  OWS     6134 non-null   float64\n",
      " 29  DWS     6134 non-null   float64\n",
      " 30  WS      6134 non-null   float64\n",
      " 31  WS/48   6134 non-null   float64\n",
      " 32  OBPM    6134 non-null   float64\n",
      " 33  DBPM    6134 non-null   float64\n",
      " 34  BPM     6134 non-null   float64\n",
      " 35  VORP    6134 non-null   float64\n",
      "dtypes: float64(32), int64(1), object(3)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "nba_data.info()\n",
    "\n",
    "# Selecting columns to keep/drop for data set\n",
    "keep_list = [25,7,0,1,3,5,6,8,9,10,11,12,13,15,17,18,20,21,23,24,26,27,28,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b05216e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PER       MPG   Age     G   GS       PPG      RPG       APG       SPG  \\\n",
      "2606  11.9  7.901639  29.0  61.0  0.0  2.311475  1.47541  0.131148  0.147541   \n",
      "\n",
      "           BPG  ...    FG    FG%   3P  3P%    FT    FT%     PFPG   TS%  USG%  \\\n",
      "2606  0.508197  ...  53.0  0.736  0.0  0.0  35.0  0.625  1.42623  0.73  11.5   \n",
      "\n",
      "      OWS  \n",
      "2606  0.7  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "### Select Player \n",
    "\n",
    "# Selecting a random player from test data set\n",
    "X_player = X_test.sample(n=1)\n",
    "\n",
    "print(X_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5dee70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5001, 21)\n",
      "(5001, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcrus\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\dcrus\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.26753739071168126\n",
      "Testing Score: 0.13351647485462326\n",
      "(5001, 21)\n",
      "(5001, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcrus\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\dcrus\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8999805549885319\n",
      "Testing Score: 0.8804477972595118\n",
      "(5001, 21)\n",
      "(5001, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcrus\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\dcrus\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8440890937767853\n",
      "Testing Score: 0.8181294294947383\n",
      "(5001, 21)\n",
      "(5001, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcrus\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\dcrus\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9964888272677578\n",
      "Testing Score: 0.9948998963935748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining dataset of chosen stats\n",
    "nba_data2 = nba_data.iloc[:,keep_list]\n",
    "\n",
    "nba_data2 = nba_data2.loc[nba_data2['MPG'] > 6]\n",
    "nba_data2.head(5)\n",
    "\n",
    "for j in range(4,8):\n",
    "\n",
    "# for j in range(4,len(nba_data2.columns)):\n",
    "# j = 21\n",
    "\n",
    "    output = nba_data2.columns[j]\n",
    "\n",
    "    # df.loc[df['column_name'] == some_value]\n",
    "\n",
    "    ### Building datasets and dropping \"Season\"\n",
    "\n",
    "    # Reserving the 2018 season for \"production\"\n",
    "    # ***Player name included\n",
    "    nba_data_prod = nba_data2[nba_data2['Season'] == 2018]\n",
    "    nba_data_prod = nba_data_prod.drop(columns=['Season'])\n",
    "\n",
    "    # Setting the remainder of data for test and train\n",
    "    nba_data_train_test = nba_data2[nba_data2['Season'] != 2018].drop(columns=[\"Player\",\"Season\"])\n",
    "\n",
    "    # renaming for ease\n",
    "    nba_tt = nba_data_train_test\n",
    "    nba_tt.head(1)\n",
    "\n",
    "    ### BUilding X and y dataframe \n",
    "\n",
    "    # Defining inputs\n",
    "    X = nba_tt.drop(columns=output)\n",
    "\n",
    "    # Defining outputs\n",
    "    y = nba_tt[[output]].values.reshape(-1,1)\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    y.max()\n",
    "\n",
    "    X\n",
    "\n",
    "    ### Starting data-modeling process \n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    ### Scaling data \n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Create a StandardScater model and fit it to the training data\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "    # Transform the training and testing data using the X_scaler\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # from sklearn.linear_model import LinearRegression\n",
    "    # model = LinearRegression()\n",
    "\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    model = MLPRegressor()\n",
    "\n",
    "    ### Model fit and score \n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    training_score = model.score(X_train_scaled, y_train)\n",
    "    testing_score = model.score(X_test_scaled, y_test)\n",
    "\n",
    "    print(f\"Training Score: {training_score}\")\n",
    "    print(f\"Testing Score: {testing_score}\")\n",
    "\n",
    "\n",
    "\n",
    "    ### Running the Loop\n",
    "\n",
    "    max_mpg = int(nba_tt[\"MPG\"].max())\n",
    "    PER_list = list()\n",
    "\n",
    "    # Building predictions based on each minute of MPG\n",
    "    for i in range(1,max_mpg+1):\n",
    "        X_player[\"MPG\"] = i\n",
    "        X_player_scaled = X_scaler.transform(X_player)\n",
    "        y_player = model.predict(X_player_scaled)\n",
    "\n",
    "        PER_list.append(y_player[0])\n",
    "\n",
    "    # PER_list\n",
    "\n",
    "    # ### Summarizing Weights for each Stat\n",
    "\n",
    "    # importance = model.coefs_\n",
    "    # importance\n",
    "    # # consider permutation feature importance \n",
    "    # # https://scikit-learn.org/stable/modules/permutation_importance.html\n",
    "\n",
    "\n",
    "    # list1 = list()\n",
    "    # list2 = list()\n",
    "\n",
    "    # for i in range(0,len(X.columns)):\n",
    "    #     list1.append(importance[0][i].round(4))\n",
    "    #     list2.append(X.columns[i])\n",
    "\n",
    "    # df = pd.DataFrame(list(zip(list1, list2)),\n",
    "    #                columns =['Weight', 'Stat']).set_index('Stat').sort_values(by='Weight',ascending=False)\n",
    "    # df.T\n",
    "\n",
    "    ###  Summarizing PER results for each potential MPG\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.scatter(range(1,max_mpg+1), PER_list, c=\"blue\", label=f\"{output} by Minute\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"MPG vs. {output}\")\n",
    "    plt.savefig(fname=f\"Figures/{output}\")\n",
    "    \n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fef5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
