{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae6af31",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92edbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nba_data = pd.read_csv(r\"seasons_clean.csv\")\n",
    "nba_data.rename(columns={\"WS/48\":\"WS48\"}, inplace=True)\n",
    "nba_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1709f8ed",
   "metadata": {},
   "source": [
    "### Selecting columns (stats) to keep in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd64253",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_list = [7,0,1,3,5,6,8,9,10,11,12,13,15,17,18,20,21,23,24,26,27,28]\n",
    "output_list = [0,25,30,31,34,35]\n",
    "\n",
    "print(f'Stat list \\n*******\\n{nba_data.columns[stat_list]}')\n",
    "print(f'\\n\\nOutput list \\n*******\\n{nba_data.columns[output_list]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094356aa",
   "metadata": {},
   "source": [
    "### Defining X y datasets (for testing/training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdcf361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dataset of chosen stats \n",
    "# (filtering out players with less than half a quarter of play)\n",
    "nba_X = nba_data.loc[nba_data['MPG'] > 6].iloc[:,stat_list]\n",
    "nba_X = nba_X[nba_X['Season'] != 2018].drop(columns=[\"Season\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining output dataset for y_train/y_test of chosen outputs \n",
    "# (filtering out players with less than half a quarter of play)\n",
    "nba_y = nba_data.loc[nba_data['MPG'] > 6].iloc[:,output_list]\n",
    "nba_y = nba_y[nba_y['Season'] != 2018].drop(columns=[\"Season\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba953e0",
   "metadata": {},
   "source": [
    "### Defining X y datasets (2018 only, for Production) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52869685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserving the 2018 season for \"production\"\n",
    "nba_2018_X = nba_data.loc[nba_data['MPG'] > 6].iloc[:,stat_list]\n",
    "nba_2018_X = nba_2018_X[nba_2018_X['Season'] == 2018].drop(columns=[\"Season\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining output dataset for y_train/y_test of chosen outputs \n",
    "# (filtering out players with less than half a quarter of play)\n",
    "nba_2018_y = nba_data.loc[nba_data['MPG'] > 6].iloc[:,output_list]\n",
    "nba_2018_y = nba_2018_y[nba_2018_y['Season'] == 2018].drop(columns=[\"Season\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa5264",
   "metadata": {},
   "source": [
    "### Defining the function to Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52033212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def Create_Model(nba_X,nba_y):\n",
    "    \n",
    "    for j in range(0,len(output_list)-1):\n",
    "        \n",
    "        output = nba_y.columns[j]\n",
    "        output_data = nba_y.iloc[:,j]\n",
    "\n",
    "        ### Building X and y dataframe \n",
    "\n",
    "        # Defining inputs\n",
    "        X = nba_X.drop(columns=[\"Player\"])\n",
    "\n",
    "        # Defining outputs\n",
    "        y = output_data.values.reshape(-1)\n",
    "\n",
    "        print(\"*********************************\")\n",
    "\n",
    "        ### Starting data-modeling process \n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "        ### Scaling data \n",
    "\n",
    "        # Create a StandardScaler model and fit it to the training data\n",
    "        X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "        # Transform the training and testing data using the X_scaler\n",
    "        X_train_scaled = X_scaler.transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "        ### Model fit and score\n",
    "\n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        model = MLPRegressor()   \n",
    "\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        training_score = model.score(X_train_scaled, y_train)\n",
    "        testing_score = model.score(X_test_scaled, y_test)\n",
    "\n",
    "        print(f\"{output} Training Score: {training_score.round(3)}\")\n",
    "        print(f\"{output} Testing Score: {testing_score.round(3)}\")\n",
    "        print(f'Saved: model_NBA_{output}.joblib')\n",
    "\n",
    "        ### SAVE MODEL\n",
    "\n",
    "        dump(model, f'Model/model_NBA_{output}.joblib') \n",
    "\n",
    "        print(\"*********************************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd73e298",
   "metadata": {},
   "source": [
    "### Create and Save the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110fef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create_Model(nba_X,nba_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ac5a0",
   "metadata": {},
   "source": [
    "### Defining the function for Permutation Importance (and apply model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def Permutation_Importance(nba_X,nba_y):\n",
    "    \n",
    "    for j in range(0,len(output_list)-1):\n",
    "\n",
    "        ### Building X and y dataframe \n",
    "        # Defining inputs\n",
    "        X = nba_X.drop(columns=[\"Player\"])\n",
    "\n",
    "        # Defining outputs\n",
    "        output = nba_y.columns[j]\n",
    "        y = nba_y.iloc[:,j].values.reshape(-1)\n",
    "\n",
    "        print(\"*********************************\")\n",
    "        print(f'{output}\\n')\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "        ### Scaling data \n",
    "        # Create a StandardScaler model and fit it to the training data\n",
    "        X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "        # Transform the training and testing data using the X_scaler\n",
    "        X_train_scaled = X_scaler.transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "        ### LOAD Model\n",
    "        model_NBA_load = load(f'Model/model_NBA_{output}.joblib') \n",
    "        print(f'Load: model_NBA_{output}.joblib')\n",
    "        \n",
    "        # Permutation Importance\n",
    "        r = permutation_importance(model_NBA_load, X_test_scaled, y_test,\n",
    "                                   n_repeats=30,\n",
    "                                   random_state=0)\n",
    "\n",
    "        for i in r.importances_mean.argsort()[::-1]:\n",
    "            if r.importances_mean[i] - 2 * r.importances_std[i] > 0:   \n",
    "                print(f\"Importance (Highest): {X_test.columns[i]}({r.importances_mean[i]:.3f})\\n\"\n",
    "                      f\"Importance ({X_test.columns[0]}): ({r.importances_mean[0]:.3f})\")\n",
    "\n",
    "            # Break in order to print only the highest importance stat\n",
    "            break \n",
    "\n",
    "        print(\"*********************************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9383688",
   "metadata": {},
   "source": [
    "### Run Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bea324",
   "metadata": {},
   "outputs": [],
   "source": [
    "Permutation_Importance(nba_X,nba_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b934a3",
   "metadata": {},
   "source": [
    "### Defining the function for Mean Efficiency Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MER(nba_2018_X, nba_2018_y):\n",
    "    \n",
    "    mean_data = pd.DataFrame(nba_2018_X.mean()).T\n",
    "    mean_output = pd.DataFrame(nba_2018_y.mean()).T\n",
    "    \n",
    "    rows = []\n",
    "    for j in range(0,len(output_list)-1):\n",
    "\n",
    "        # Defining inputs\n",
    "        mean_data_test = mean_data\n",
    "\n",
    "        X = nba_2018_X.drop(columns=[\"Player\"])\n",
    "\n",
    "        # Defining outputs  \n",
    "        output = nba_2018_y.columns[j]\n",
    "        y = nba_2018_y.iloc[:,j].values.reshape(-1)        \n",
    "\n",
    "        ### LOAD Model\n",
    "        model_NBA_load = load(f'Model/model_NBA_{output}.joblib') \n",
    "\n",
    "        ### Scaling data \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "        X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "        # Gathering MEAN data\n",
    "        mean_data_scaled = X_scaler.transform(mean_data_test)\n",
    "        y_mean = model_NBA_load.predict(mean_data_scaled)\n",
    "\n",
    "        print(\"*****************\")\n",
    "        print(f\"{output}\")\n",
    "\n",
    "        y_mean_value = y_mean[0]\n",
    "        print(f\"Predicted = {y_mean_value:.2f}\")\n",
    "\n",
    "        y_actual = mean_output.iloc[0][output]\n",
    "        print(f\"Actual = {y_actual:.2f}\")\n",
    "\n",
    "        dif = ((y_mean_value - y_actual)/y_actual)*100\n",
    "        print(f\"MER: {dif:.2f}%\")\n",
    "\n",
    "        print(\"*****************\")\n",
    "\n",
    "        rows.append([output,round(y_mean_value,2), round(y_actual,2), round(dif,1)])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['Output','Predicted','Actual','% Diff'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ddaa44",
   "metadata": {},
   "source": [
    "### Run Mean Efficiency Rating on 2018 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "MER(nba_2018_X, nba_2018_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8962e",
   "metadata": {},
   "source": [
    "### Run Mean Efficiency Rating on Train/Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MER(nba_X, nba_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1d94a2",
   "metadata": {},
   "source": [
    "# \n",
    "# Production "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09015395",
   "metadata": {},
   "source": [
    "### Define Roster to Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptors = [\"OG Anunoby\",\"Marc Gasol\",\"Danny Green\", \"Serge Ibaka\", \"Kawhi Leonard\",\n",
    "           \"Jeremy Lin\",\"Kyle Lowry\",\"Norman Powell\", \"Pascal Siakam\", \n",
    "           \"Fred VanVleet\", \"Delon Wright\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7d840",
   "metadata": {},
   "source": [
    "### Function to Select Player to Evaluate with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectPlayer(x):\n",
    "    \n",
    "    # Enter player as string in function above\n",
    "    player = x\n",
    "    player_prod = nba_2018_X[nba_2018_X['Player'] == player].drop(columns=[\"Player\"])\n",
    "    \n",
    "    Production(player_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba296b9",
   "metadata": {},
   "source": [
    "### Defining function to evaluate players in Production environment with Saved Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Production(player_prod):\n",
    "    # Setting Players actual MPG value\n",
    "    v = player_prod['MPG'].values[0]\n",
    "    print(f\"Actual MPG: {v}\")\n",
    "    total_max = 0\n",
    "    total_min = 0\n",
    "    \n",
    "    for j in range(0,len(output_list)-1):\n",
    "\n",
    "        ### Building X and y dataframe \n",
    "        # Defining inputs\n",
    "        X = nba_2018_X.drop(columns=[\"Player\"])\n",
    "        X_prod_2018 = player_prod\n",
    "\n",
    "        # Defining outputs\n",
    "        output = nba_2018_y.columns[j]\n",
    "        y = nba_2018_y.iloc[:,j].values.reshape(-1)\n",
    "\n",
    "        ### LOAD Model\n",
    "\n",
    "        model_NBA_load = load(f'Model/model_NBA_{output}.joblib') \n",
    "\n",
    "        pos = player_prod.iloc[0,2]\n",
    "        print(f'Evaluated {output} for {player} (2018)')\n",
    "\n",
    "        ### Scaling data \n",
    "\n",
    "        # Create a StandardScaler model and fit it to the training data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "        X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "        ### Running the MPG Loop\n",
    "\n",
    "        max_mpg = int(nba_X[\"MPG\"].max())\n",
    "        PER_list = list()\n",
    "\n",
    "        # Building predictions based on each minute of MPG\n",
    "        for i in range(7,max_mpg+1):\n",
    "\n",
    "            # Gathering player data\n",
    "            player_prod[\"MPG\"] = i\n",
    "            X_player_scaled_2018 = X_scaler.transform(player_prod)\n",
    "            y_player_2018 = model_NBA_load.predict(X_player_scaled_2018)\n",
    "\n",
    "            PER_list.append(y_player_2018[0])\n",
    "\n",
    "        # Scale results\n",
    "        myInt = max(PER_list)\n",
    "        PER_list[:] = [x / myInt for x in PER_list]\n",
    "        \n",
    "        # Grabbing max and min values to set for vertical line\n",
    "        total_max = max(total_max,max(PER_list))\n",
    "        total_min = min(total_min,min(PER_list))\n",
    "        \n",
    "        \n",
    "        ### PLOT THE RESULTS\n",
    "        \n",
    "        colors = [\"b\",\"g\",\"r\",\"c\",\"m\"]\n",
    "        \n",
    "        plt.scatter(range(7,max_mpg+1), PER_list, c=colors[j], label=f\"{output}\")\n",
    "        plt.title(f\"2018 - MPG Impact for {player}\")\n",
    "    plt.vlines(v, total_min, total_max, label=f'MPG')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(fname=f\"Figures/AllStats_for_{player}\",facecolor=\"lightsteelblue\")\n",
    "\n",
    "    ### Clear the figure for loop\n",
    "    plt.clf()\n",
    "    print(\"********************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e582f",
   "metadata": {},
   "source": [
    "### Generating plots of MPG impact on Player Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173427c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for player in raptors:  \n",
    "    SelectPlayer(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8becab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = \"Stephen Curry\"\n",
    "\n",
    "SelectPlayer(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24121cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
